{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-13T12:02:29.328835Z",
     "iopub.status.busy": "2025-08-13T12:02:29.328565Z",
     "iopub.status.idle": "2025-08-13T12:02:29.334064Z",
     "shell.execute_reply": "2025-08-13T12:02:29.333222Z",
     "shell.execute_reply.started": "2025-08-13T12:02:29.328815Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os, re, math, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-13T12:02:29.335406Z",
     "iopub.status.busy": "2025-08-13T12:02:29.335152Z",
     "iopub.status.idle": "2025-08-13T12:02:29.348616Z",
     "shell.execute_reply": "2025-08-13T12:02:29.348032Z",
     "shell.execute_reply.started": "2025-08-13T12:02:29.335385Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "SEED = 52\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "IMDB_CSV = \"/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\"\n",
    "GLOVE_TXT = \"/kaggle/input/glove-global-vectors-for-word-representation/glove.6B.100d.txt\" \n",
    "\n",
    "MAX_VOCAB = 25000\n",
    "MIN_FREQ = 2\n",
    "MAX_LEN = 400              \n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 5                 \n",
    "LR = 1e-3\n",
    "EMB_DIM = 100              \n",
    "HIDDEN = 128\n",
    "DROPOUT = 0.2              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-13T12:02:29.350061Z",
     "iopub.status.busy": "2025-08-13T12:02:29.349862Z",
     "iopub.status.idle": "2025-08-13T12:02:29.973749Z",
     "shell.execute_reply": "2025-08-13T12:02:29.973174Z",
     "shell.execute_reply.started": "2025-08-13T12:02:29.350047Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(IMDB_CSV)\n",
    "df[\"label\"] = df[\"sentiment\"].map({\"positive\": 1, \"negative\": 0}).astype(np.float32)\n",
    "\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df[\"review\"].values, df[\"label\"].values, test_size=0.2, random_state=SEED, stratify=df[\"label\"].values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-13T12:02:29.975566Z",
     "iopub.status.busy": "2025-08-13T12:02:29.975391Z",
     "iopub.status.idle": "2025-08-13T12:02:29.979405Z",
     "shell.execute_reply": "2025-08-13T12:02:29.978711Z",
     "shell.execute_reply.started": "2025-08-13T12:02:29.975553Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "_tok = re.compile(r\"[A-Za-z0-9']+\")\n",
    "def tokenize(s: str):\n",
    "    return _tok.findall(s.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-13T12:02:29.981312Z",
     "iopub.status.busy": "2025-08-13T12:02:29.981071Z",
     "iopub.status.idle": "2025-08-13T12:02:33.854319Z",
     "shell.execute_reply": "2025-08-13T12:02:33.853587Z",
     "shell.execute_reply.started": "2025-08-13T12:02:29.981296Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 25000 | PAD=0 UNK=1\n"
     ]
    }
   ],
   "source": [
    "train_tokens = [tokenize(t) for t in train_texts]\n",
    "\n",
    "counts = Counter()\n",
    "for toks in train_tokens:\n",
    "    counts.update(toks)\n",
    "\n",
    "specials = [\"<pad>\", \"<unk>\"]\n",
    "most_common = [w for w, c in counts.items() if c >= MIN_FREQ]\n",
    "most_common = sorted(most_common, key=lambda w: counts[w], reverse=True)[: MAX_VOCAB - len(specials)]\n",
    "\n",
    "itos = specials + most_common\n",
    "stoi = {w: i for i, w in enumerate(itos)}\n",
    "PAD_IDX, UNK_IDX = stoi[\"<pad>\"], stoi[\"<unk>\"]\n",
    "\n",
    "def encode(tokens):\n",
    "    ids = [stoi.get(t, UNK_IDX) for t in tokens]\n",
    "    if len(ids) > MAX_LEN:\n",
    "        ids = ids[:MAX_LEN]\n",
    "    return torch.tensor(ids, dtype=torch.long)\n",
    "\n",
    "print(f\"Vocab size: {len(itos)} | PAD={PAD_IDX} UNK={UNK_IDX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-13T12:02:33.855454Z",
     "iopub.status.busy": "2025-08-13T12:02:33.855136Z",
     "iopub.status.idle": "2025-08-13T12:02:36.989960Z",
     "shell.execute_reply": "2025-08-13T12:02:36.989380Z",
     "shell.execute_reply.started": "2025-08-13T12:02:33.855436Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_ids = [encode(toks) for toks in train_tokens]\n",
    "test_ids  = [encode(tokenize(t)) for t in test_texts]\n",
    "\n",
    "y_train = torch.tensor(train_labels, dtype=torch.float32)\n",
    "y_test  = torch.tensor(test_labels, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-13T12:02:36.990861Z",
     "iopub.status.busy": "2025-08-13T12:02:36.990655Z",
     "iopub.status.idle": "2025-08-13T12:02:36.996089Z",
     "shell.execute_reply": "2025-08-13T12:02:36.995433Z",
     "shell.execute_reply.started": "2025-08-13T12:02:36.990845Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ListDataset(Dataset):\n",
    "    def __init__(self, seqs, labels):\n",
    "        self.seqs = seqs\n",
    "        self.labels = labels\n",
    "    def __len__(self):\n",
    "        return len(self.seqs)\n",
    "    def __getitem__(self, i):\n",
    "        return self.seqs[i], self.labels[i]\n",
    "\n",
    "def collate_batch(batch):\n",
    "    seqs, labels = zip(*batch)\n",
    "    lengths = torch.tensor([len(s) for s in seqs], dtype=torch.long)\n",
    "    padded = pad_sequence(seqs, batch_first=True, padding_value=PAD_IDX)\n",
    "    labels = torch.stack([torch.tensor(l) for l in labels])\n",
    "    return padded, lengths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-13T12:02:36.997094Z",
     "iopub.status.busy": "2025-08-13T12:02:36.996881Z",
     "iopub.status.idle": "2025-08-13T12:02:37.064604Z",
     "shell.execute_reply": "2025-08-13T12:02:37.064043Z",
     "shell.execute_reply.started": "2025-08-13T12:02:36.997080Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_ds = ListDataset(train_ids, y_train)\n",
    "test_ds  = ListDataset(test_ids,  y_test)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-13T12:02:37.067736Z",
     "iopub.status.busy": "2025-08-13T12:02:37.067514Z",
     "iopub.status.idle": "2025-08-13T12:02:37.077206Z",
     "shell.execute_reply": "2025-08-13T12:02:37.076565Z",
     "shell.execute_reply.started": "2025-08-13T12:02:37.067720Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_glove_matrix(glove_txt_path, itos, emb_dim=100, pad_idx=0, unk_idx=1):\n",
    "\n",
    "    g = {}\n",
    "    with open(glove_txt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            parts = line.rstrip().split(\" \")\n",
    "            w = parts[0]\n",
    "            vec = np.asarray(parts[1:], dtype=\"float32\")\n",
    "            if vec.shape[0] == emb_dim:\n",
    "                g[w] = vec\n",
    "\n",
    "    matrix = np.random.normal(scale=0.6, size=(len(itos), emb_dim)).astype(\"float32\")\n",
    "    for i, w in enumerate(itos):\n",
    "        if w in g:\n",
    "            matrix[i] = g[w]\n",
    "    matrix[pad_idx] = 0.0\n",
    "    return torch.tensor(matrix, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-13T12:02:37.078108Z",
     "iopub.status.busy": "2025-08-13T12:02:37.077925Z",
     "iopub.status.idle": "2025-08-13T12:02:37.085537Z",
     "shell.execute_reply": "2025-08-13T12:02:37.084909Z",
     "shell.execute_reply.started": "2025-08-13T12:02:37.078094Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class VanillaRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, hidden, dropout=0.0, pad_idx=0, pretrained=None, freeze=True):\n",
    "        super().__init__()\n",
    "        if pretrained is None:\n",
    "            self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=pad_idx)\n",
    "        else:\n",
    "            self.embedding = nn.Embedding.from_pretrained(pretrained, freeze=freeze, padding_idx=pad_idx)\n",
    "        self.rnn = nn.RNN(emb_dim, hidden, batch_first=True)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden, 1)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        emb = self.embedding(x)\n",
    "        packed = pack_padded_sequence(emb, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        _, h_n = self.rnn(packed)\n",
    "        out = self.drop(h_n[-1])\n",
    "        return self.fc(out).squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-13T12:02:37.087616Z",
     "iopub.status.busy": "2025-08-13T12:02:37.087351Z",
     "iopub.status.idle": "2025-08-13T12:02:37.096934Z",
     "shell.execute_reply": "2025-08-13T12:02:37.096385Z",
     "shell.execute_reply.started": "2025-08-13T12:02:37.087599Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class LSTMNet(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, hidden, dropout=0.0, pad_idx=0, pretrained=None, freeze=True):\n",
    "        super().__init__()\n",
    "        if pretrained is None:\n",
    "            self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=pad_idx)\n",
    "        else:\n",
    "            self.embedding = nn.Embedding.from_pretrained(pretrained, freeze=freeze, padding_idx=pad_idx)\n",
    "        self.lstm = nn.LSTM(emb_dim, hidden, batch_first=True)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden, 1)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        emb = self.embedding(x)\n",
    "        packed = pack_padded_sequence(emb, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        _, (h_n, _) = self.lstm(packed)\n",
    "        out = self.drop(h_n[-1])\n",
    "        return self.fc(out).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-13T12:02:37.098030Z",
     "iopub.status.busy": "2025-08-13T12:02:37.097776Z",
     "iopub.status.idle": "2025-08-13T12:02:37.110622Z",
     "shell.execute_reply": "2025-08-13T12:02:37.110017Z",
     "shell.execute_reply.started": "2025-08-13T12:02:37.098008Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optim, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for x, lengths, y in loader:\n",
    "        x, lengths, y = x.to(DEVICE), lengths.to(DEVICE), y.to(DEVICE)\n",
    "        optim.zero_grad()\n",
    "        logits = model(x, lengths)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / max(1, len(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-13T12:02:37.111641Z",
     "iopub.status.busy": "2025-08-13T12:02:37.111424Z",
     "iopub.status.idle": "2025-08-13T12:02:37.121786Z",
     "shell.execute_reply": "2025-08-13T12:02:37.121056Z",
     "shell.execute_reply.started": "2025-08-13T12:02:37.111625Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_preds, all_labels = [], []\n",
    "    for x, lengths, y in loader:\n",
    "        x, lengths, y = x.to(DEVICE), lengths.to(DEVICE), y.to(DEVICE)\n",
    "        logits = model(x, lengths)\n",
    "        loss = criterion(logits, y)\n",
    "        total_loss += loss.item()\n",
    "        probs = torch.sigmoid(logits)\n",
    "        preds = (probs >= 0.5).long().cpu().numpy()\n",
    "        all_preds.extend(preds.tolist())\n",
    "        all_labels.extend(y.long().cpu().numpy().tolist())\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    return total_loss / max(1, len(loader)), acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-13T12:02:37.122714Z",
     "iopub.status.busy": "2025-08-13T12:02:37.122533Z",
     "iopub.status.idle": "2025-08-13T12:02:37.131843Z",
     "shell.execute_reply": "2025-08-13T12:02:37.131260Z",
     "shell.execute_reply.started": "2025-08-13T12:02:37.122699Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def run_experiment(model_name, use_glove, freeze=True, epochs=EPOCHS):\n",
    "    pretrained = None\n",
    "    if use_glove:\n",
    "        pretrained = load_glove_matrix(GLOVE_TXT, itos, emb_dim=EMB_DIM, pad_idx=PAD_IDX, unk_idx=UNK_IDX)\n",
    "\n",
    "    if model_name == \"rnn\":\n",
    "        model = VanillaRNN(\n",
    "            vocab_size=len(itos), emb_dim=EMB_DIM, hidden=HIDDEN,\n",
    "            dropout=DROPOUT, pad_idx=PAD_IDX, pretrained=pretrained, freeze=freeze\n",
    "        )\n",
    "    elif model_name == \"lstm\":\n",
    "        model = LSTMNet(\n",
    "            vocab_size=len(itos), emb_dim=EMB_DIM, hidden=HIDDEN,\n",
    "            dropout=DROPOUT, pad_idx=PAD_IDX, pretrained=pretrained, freeze=freeze\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"model_name must be 'rnn' or 'lstm'\")\n",
    "\n",
    "    model.to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    print(f\"\\n=== {model_name.upper()} | {'GloVe' if use_glove else 'Learned'} Embeddings | freeze={freeze} ===\")\n",
    "    for ep in range(1, epochs + 1):\n",
    "        tr_loss = train_epoch(model, train_loader, optimizer, criterion)\n",
    "        val_loss, val_acc = evaluate(model, test_loader, criterion)\n",
    "        print(f\"Epoch {ep:02d} | train_loss={tr_loss:.4f} | val_loss={val_loss:.4f} | val_acc={val_acc:.4f}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-13T12:02:37.133261Z",
     "iopub.status.busy": "2025-08-13T12:02:37.132735Z",
     "iopub.status.idle": "2025-08-13T12:06:41.859853Z",
     "shell.execute_reply": "2025-08-13T12:06:41.859217Z",
     "shell.execute_reply.started": "2025-08-13T12:02:37.133237Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RNN | GloVe Embeddings | freeze=True ===\n",
      "Epoch 01 | train_loss=0.6685 | val_loss=0.6740 | val_acc=0.5898\n",
      "Epoch 02 | train_loss=0.6799 | val_loss=0.7655 | val_acc=0.5133\n",
      "Epoch 03 | train_loss=0.6694 | val_loss=0.6687 | val_acc=0.5799\n",
      "Epoch 04 | train_loss=0.6543 | val_loss=0.7176 | val_acc=0.5595\n",
      "Epoch 05 | train_loss=0.6700 | val_loss=0.6764 | val_acc=0.5682\n",
      "\n",
      "=== LSTM | GloVe Embeddings | freeze=True ===\n",
      "Epoch 01 | train_loss=0.6573 | val_loss=0.6636 | val_acc=0.6036\n",
      "Epoch 02 | train_loss=0.6256 | val_loss=0.4773 | val_acc=0.7857\n",
      "Epoch 03 | train_loss=0.4077 | val_loss=0.3571 | val_acc=0.8413\n",
      "Epoch 04 | train_loss=0.3497 | val_loss=0.3241 | val_acc=0.8590\n",
      "Epoch 05 | train_loss=0.3229 | val_loss=0.3037 | val_acc=0.8680\n",
      "\n",
      "=== RNN | Learned Embeddings | freeze=True ===\n",
      "Epoch 01 | train_loss=0.6478 | val_loss=0.6035 | val_acc=0.6802\n",
      "Epoch 02 | train_loss=0.5912 | val_loss=0.5659 | val_acc=0.7246\n",
      "Epoch 03 | train_loss=0.5643 | val_loss=0.6070 | val_acc=0.6648\n",
      "Epoch 04 | train_loss=0.4953 | val_loss=0.4897 | val_acc=0.7896\n",
      "Epoch 05 | train_loss=0.5510 | val_loss=0.6014 | val_acc=0.6686\n",
      "\n",
      "=== LSTM | Learned Embeddings | freeze=True ===\n",
      "Epoch 01 | train_loss=0.6026 | val_loss=0.5315 | val_acc=0.7378\n",
      "Epoch 02 | train_loss=0.5258 | val_loss=0.4463 | val_acc=0.8058\n",
      "Epoch 03 | train_loss=0.4922 | val_loss=0.4430 | val_acc=0.7958\n",
      "Epoch 04 | train_loss=0.3238 | val_loss=0.3070 | val_acc=0.8745\n",
      "Epoch 05 | train_loss=0.2379 | val_loss=0.2981 | val_acc=0.8759\n"
     ]
    }
   ],
   "source": [
    "# 1) GloVe + Vanilla RNN (frozen embeddings)\n",
    "model_rnn_glove = run_experiment(\"rnn\", use_glove=True, freeze=True)\n",
    "\n",
    "# 2) GloVe + LSTM (frozen embeddings)\n",
    "model_lstm_glove = run_experiment(\"lstm\", use_glove=True, freeze=True)\n",
    "\n",
    "# 3) Learned Embedding + RNN\n",
    "model_rnn_learned = run_experiment(\"rnn\", use_glove=False)\n",
    "\n",
    "# 4) Learned Embedding + LSTM\n",
    "model_lstm_learned = run_experiment(\"lstm\", use_glove=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-13T12:06:41.861379Z",
     "iopub.status.busy": "2025-08-13T12:06:41.860687Z",
     "iopub.status.idle": "2025-08-13T12:06:46.131098Z",
     "shell.execute_reply": "2025-08-13T12:06:46.130489Z",
     "shell.execute_reply.started": "2025-08-13T12:06:41.861359Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Architecture</th>\n",
       "      <th>Embeddings</th>\n",
       "      <th>Val Loss</th>\n",
       "      <th>Val Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vanilla RNN</td>\n",
       "      <td>GloVe (frozen)</td>\n",
       "      <td>0.6764</td>\n",
       "      <td>56.82%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>GloVe (frozen)</td>\n",
       "      <td>0.3037</td>\n",
       "      <td>86.80%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vanilla RNN</td>\n",
       "      <td>Learned (nn.Embedding)</td>\n",
       "      <td>0.6014</td>\n",
       "      <td>66.86%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>Learned (nn.Embedding)</td>\n",
       "      <td>0.2981</td>\n",
       "      <td>87.59%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Architecture              Embeddings  Val Loss Val Accuracy\n",
       "0  Vanilla RNN          GloVe (frozen)    0.6764       56.82%\n",
       "1         LSTM          GloVe (frozen)    0.3037       86.80%\n",
       "2  Vanilla RNN  Learned (nn.Embedding)    0.6014       66.86%\n",
       "3         LSTM  Learned (nn.Embedding)    0.2981       87.59%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "rows = []\n",
    "for arch, emb_name, mdl in [\n",
    "    (\"Vanilla RNN\", \"GloVe (frozen)\",  model_rnn_glove),\n",
    "    (\"LSTM\",        \"GloVe (frozen)\",  model_lstm_glove),\n",
    "    (\"Vanilla RNN\", \"Learned (nn.Embedding)\", model_rnn_learned),\n",
    "    (\"LSTM\",        \"Learned (nn.Embedding)\", model_lstm_learned),\n",
    "]:\n",
    "    val_loss, val_acc = evaluate(mdl, test_loader, criterion)  # returns (loss, accuracy)\n",
    "    rows.append({\n",
    "        \"Architecture\": arch,\n",
    "        \"Embeddings\": emb_name,\n",
    "        \"Val Loss\": round(val_loss, 4),\n",
    "        \"Val Accuracy\": f\"{val_acc * 100:.2f}%\",\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(rows, columns=[\"Architecture\", \"Embeddings\", \"Val Loss\", \"Val Accuracy\"])\n",
    "\n",
    "try:\n",
    "    from IPython.display import display\n",
    "    display(results_df)\n",
    "except:\n",
    "    print(results_df.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 134715,
     "sourceId": 320111,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1835,
     "sourceId": 3176,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
